{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T19:13:06.746790Z",
     "start_time": "2024-12-05T19:13:06.721784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, List, Tuple\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FineTuneConfig:\n",
    "    \"\"\"\n",
    "    Configuración para el fine-tuning del modelo.\n",
    "    \"\"\"\n",
    "    model_name: str\n",
    "    output_dir: str\n",
    "    max_source_length: int = 1024\n",
    "    max_target_length: int = 128\n",
    "    batch_size: int = 4\n",
    "    num_train_epochs: int = 1\n",
    "    learning_rate: float = 2e-5\n",
    "    weight_decay: float = 0.01\n",
    "    warmup_steps: int = 500\n",
    "    logging_steps: int = 500\n",
    "    save_steps: int = 2000\n",
    "    evaluation_strategy: str = \"epoch\"\n",
    "    predict_with_generate: bool = True\n",
    "    num_beams: int = 4\n",
    "\n",
    "\n",
    "class SummarizationPreprocessor:\n",
    "    \"\"\"\n",
    "    Clase para preprocesar el dataset CNN/DailyMail para tareas de resumen, \n",
    "    tokenizando entradas y preparando etiquetas.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            tokenizer,\n",
    "            max_source_length: int = 1024,\n",
    "            max_target_length: int = 128\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Inicializa el preprocesador.\n",
    "\n",
    "        Args:\n",
    "            tokenizer: Instancia de tokenizer de Hugging Face.\n",
    "            max_source_length (int): Longitud máxima de la entrada.\n",
    "            max_target_length (int): Longitud máxima del resumen.\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def preprocess_batch(self, batch: Dict[str, List[str]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Preprocesa un batch de datos del dataset CNN/DailyMail.\n",
    "\n",
    "        Args:\n",
    "            batch (Dict[str, List[str]]): Batch con claves \"article\" y \"highlights\".\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: Diccionario con entradas tokenizadas y etiquetas.\n",
    "        \"\"\"\n",
    "        inputs = batch[\"article\"]\n",
    "        targets = batch[\"highlights\"]\n",
    "        model_inputs = self.tokenizer(\n",
    "            inputs,\n",
    "            max_length=self.max_source_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",  # Padding para que todas las secuencias tengan la misma longitud\n",
    "            return_tensors=\"pt\"  # Retorna tensores PyTorch directamente\n",
    "        )\n",
    "        model_inputs[\"labels\"] = self.tokenizer(\n",
    "            targets,\n",
    "            max_length=self.max_target_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",  # Padding para las etiquetas\n",
    "            return_tensors=\"pt\"  # Retorna tensores PyTorch directamente\n",
    "        )[\"input_ids\"]\n",
    "        return model_inputs\n",
    "\n",
    "\n",
    "class SummarizationModel:\n",
    "    \"\"\"\n",
    "    Clase para encapsular la carga del modelo y el tokenizer,\n",
    "    facilitando la inicialización de diferentes LLM (T5, BART, PEGASUS).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name (str): Nombre del modelo en Hugging Face Hub.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    def get_components(self) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Retorna el tokenizer y el modelo.\n",
    "\n",
    "        Returns:\n",
    "            (tokenizer, model)\n",
    "        \"\"\"\n",
    "        return self.tokenizer, self.model\n",
    "\n",
    "\n",
    "class SummarizationTrainer:\n",
    "    \"\"\"\n",
    "    Clase responsable de entrenar, evaluar y guardar el modelo de resumen.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name: str,\n",
    "            config: FineTuneConfig,\n",
    "            train_dataset,\n",
    "            val_dataset,\n",
    "            metric_name: str = \"rouge\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Inicializa el entrenador para el modelo de resumen.\n",
    "\n",
    "        Args:\n",
    "            model_name (str): Nombre del modelo en Hugging Face Hub.\n",
    "            config (FineTuneConfig): Configuración de fine-tuning.\n",
    "            train_dataset: Dataset de entrenamiento tokenizado.\n",
    "            val_dataset: Dataset de validación tokenizado.\n",
    "            metric_name (str): Nombre de la métrica a cargar (por defecto, 'rouge').\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.config = config\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.metric = evaluate.load(metric_name)\n",
    "        self.tokenizer, self.model = SummarizationModel(model_name).get_components()\n",
    "\n",
    "        self.data_collator = DataCollatorForSeq2Seq(\n",
    "            self.tokenizer, model=self.model, padding=\"longest\"\n",
    "        )\n",
    "\n",
    "        self.training_args = TrainingArguments(\n",
    "            output_dir=self.config.output_dir,\n",
    "            evaluation_strategy=self.config.evaluation_strategy,\n",
    "            per_device_train_batch_size=self.config.batch_size,\n",
    "            per_device_eval_batch_size=self.config.batch_size,\n",
    "            learning_rate=self.config.learning_rate,\n",
    "            weight_decay=self.config.weight_decay,\n",
    "            num_train_epochs=self.config.num_train_epochs,\n",
    "            warmup_steps=self.config.warmup_steps,\n",
    "            logging_steps=self.config.logging_steps,\n",
    "            save_steps=self.config.save_steps,\n",
    "            predict_with_generate=self.config.predict_with_generate,\n",
    "            report_to=\"none\",\n",
    "            overwrite_output_dir=True\n",
    "        )\n",
    "\n",
    "    def compute_metrics(self, eval_preds):\n",
    "        \"\"\"\n",
    "        Computa métricas a partir de las predicciones del modelo.\n",
    "\n",
    "        Args:\n",
    "            eval_preds: Tupla (predictions, labels) del conjunto de validación.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, float]: Métricas calculadas (ROUGE).\n",
    "        \"\"\"\n",
    "        preds, labels = eval_preds\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "        decoded_preds = self.tokenizer.batch_decode(\n",
    "            preds, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "        decoded_labels = self.tokenizer.batch_decode(\n",
    "            labels, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "\n",
    "        # ROUGE eval\n",
    "        result = self.metric.compute(\n",
    "            predictions=decoded_preds,\n",
    "            references=decoded_labels,\n",
    "            use_stemmer=True\n",
    "        )\n",
    "        # Promediar y redondear\n",
    "        result = {k: round(v.mid.fmeasure * 100, 2) for k, v in result.items()}\n",
    "        return result\n",
    "\n",
    "    def train_and_evaluate(self):\n",
    "        \"\"\"\n",
    "        Entrena el modelo y lo evalúa en el conjunto de validación,\n",
    "        luego guarda el modelo fine-tuneado.\n",
    "        \"\"\"\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=self.training_args,\n",
    "            train_dataset=self.train_dataset,\n",
    "            eval_dataset=self.val_dataset,\n",
    "            tokenizer=self.tokenizer,\n",
    "            data_collator=self.data_collator,\n",
    "            compute_metrics=self.compute_metrics\n",
    "        )\n",
    "        trainer.train()\n",
    "        eval_results = trainer.evaluate()\n",
    "        print(f\"Evaluation results for {self.model_name}: {eval_results}\")\n",
    "\n",
    "        # Guardar el modelo fine-tuneado\n",
    "        trainer.save_model(self.config.output_dir)\n",
    "        self.tokenizer.save_pretrained(self.config.output_dir)\n",
    "        print(f\"Modelo guardado en: {self.config.output_dir}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta el pipeline de:\n",
    "    1. Carga y preprocesamiento del dataset CNN/DailyMail.\n",
    "    2. Entrenamiento y evaluación de T5, BART y PEGASUS.\n",
    "    3. Guardado de los modelos fine-tuneados.\n",
    "    \"\"\"\n",
    "    # Carga el dataset\n",
    "    dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "    train_dataset_raw = dataset[\"train\"]\n",
    "    val_dataset_raw = dataset[\"validation\"]\n",
    "\n",
    "    # Configuraciones de cada modelo\n",
    "    models_to_train = [\n",
    "        {\n",
    "            \"model_name\": \"google-t5/t5-large\",\n",
    "            \"output_dir\": \"resources/t5_finetuned_cnn\",\n",
    "        },\n",
    "        {\n",
    "            \"model_name\": \"facebook/bart-large\",\n",
    "            \"output_dir\": \"resources/bart_finetuned_cnn\",\n",
    "        },\n",
    "        {\n",
    "            \"model_name\": \"google/pegasus-large\",\n",
    "            \"output_dir\": \"resources/pegasus_finetuned_cnn\",\n",
    "        }\n",
    "    ]\n",
    "    # t5-small\n",
    "    # facebook/bart-large-cnn\n",
    "    # google/pegasus-cnn_dailymail\n",
    "\n",
    "    for model_info in models_to_train:\n",
    "        model_name = model_info[\"model_name\"]\n",
    "        output_dir = model_info[\"output_dir\"]\n",
    "\n",
    "        # Inicializar preprocesador\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "        preprocessor = SummarizationPreprocessor(\n",
    "            tokenizer=tokenizer,\n",
    "            max_source_length=1024,\n",
    "            max_target_length=128\n",
    "        )\n",
    "\n",
    "        # Tokenizar datasets\n",
    "        tokenized_train = train_dataset_raw.map(\n",
    "            preprocessor.preprocess_batch,\n",
    "            batched=True,\n",
    "            remove_columns=[\"article\", \"highlights\", \"id\"]\n",
    "        )\n",
    "        tokenized_val = val_dataset_raw.map(\n",
    "            preprocessor.preprocess_batch,\n",
    "            batched=True,\n",
    "            remove_columns=[\"article\", \"highlights\", \"id\"]\n",
    "        )\n",
    "\n",
    "        tokenized_train.set_format(\"torch\")\n",
    "        tokenized_val.set_format(\"torch\")\n",
    "\n",
    "        # Crear config de fine-tuning\n",
    "        config = FineTuneConfig(\n",
    "            model_name=model_name,\n",
    "            output_dir=output_dir,\n",
    "            max_source_length=1024,\n",
    "            max_target_length=128,\n",
    "            batch_size=2,  # Ajustar según recursos\n",
    "            num_train_epochs=1,  # Ajustar según tiempo y recursos\n",
    "            learning_rate=2e-5,\n",
    "            weight_decay=0.01,\n",
    "            warmup_steps=500,\n",
    "            logging_steps=500,\n",
    "            save_steps=2000,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            predict_with_generate=True,\n",
    "            num_beams=4\n",
    "        )\n",
    "\n",
    "        # Entrenar y evaluar el modelo\n",
    "        trainer = SummarizationTrainer(\n",
    "            model_name=model_name,\n",
    "            config=config,\n",
    "            train_dataset=tokenized_train,\n",
    "            val_dataset=tokenized_val\n",
    "        )\n",
    "        trainer.train_and_evaluate()\n"
   ],
   "id": "6705c51901ad9773",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T19:13:22.206398Z",
     "start_time": "2024-12-05T19:13:06.747793Z"
    }
   },
   "cell_type": "code",
   "source": "main()",
   "id": "50d119863a3a7c10",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2558e11328f46718aefcc8981cf5fb6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[20], line 261\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m    254\u001B[0m preprocessor \u001B[38;5;241m=\u001B[39m SummarizationPreprocessor(\n\u001B[0;32m    255\u001B[0m     tokenizer\u001B[38;5;241m=\u001B[39mtokenizer,\n\u001B[0;32m    256\u001B[0m     max_source_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1024\u001B[39m,\n\u001B[0;32m    257\u001B[0m     max_target_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m\n\u001B[0;32m    258\u001B[0m )\n\u001B[0;32m    260\u001B[0m \u001B[38;5;66;03m# Tokenizar datasets\u001B[39;00m\n\u001B[1;32m--> 261\u001B[0m tokenized_train \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_dataset_raw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    262\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreprocessor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreprocess_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    264\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremove_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43marticle\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhighlights\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m    265\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    266\u001B[0m tokenized_val \u001B[38;5;241m=\u001B[39m val_dataset_raw\u001B[38;5;241m.\u001B[39mmap(\n\u001B[0;32m    267\u001B[0m     preprocessor\u001B[38;5;241m.\u001B[39mpreprocess_batch,\n\u001B[0;32m    268\u001B[0m     batched\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    269\u001B[0m     remove_columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marticle\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhighlights\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    270\u001B[0m )\n\u001B[0;32m    272\u001B[0m tokenized_train\u001B[38;5;241m.\u001B[39mset_format(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Tesis\\.venv\\lib\\site-packages\\datasets\\arrow_dataset.py:560\u001B[0m, in \u001B[0;36mtransmit_format.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    553\u001B[0m self_format \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    554\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_type,\n\u001B[0;32m    555\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_kwargs,\n\u001B[0;32m    556\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_columns,\n\u001B[0;32m    557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_all_columns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_all_columns,\n\u001B[0;32m    558\u001B[0m }\n\u001B[0;32m    559\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[1;32m--> 560\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    561\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[0;32m    562\u001B[0m \u001B[38;5;66;03m# re-apply format to the output\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Tesis\\.venv\\lib\\site-packages\\datasets\\arrow_dataset.py:3055\u001B[0m, in \u001B[0;36mDataset.map\u001B[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001B[0m\n\u001B[0;32m   3049\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transformed_dataset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3050\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m hf_tqdm(\n\u001B[0;32m   3051\u001B[0m         unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m examples\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   3052\u001B[0m         total\u001B[38;5;241m=\u001B[39mpbar_total,\n\u001B[0;32m   3053\u001B[0m         desc\u001B[38;5;241m=\u001B[39mdesc \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMap\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   3054\u001B[0m     ) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[1;32m-> 3055\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m rank, done, content \u001B[38;5;129;01min\u001B[39;00m Dataset\u001B[38;5;241m.\u001B[39m_map_single(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdataset_kwargs):\n\u001B[0;32m   3056\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m done:\n\u001B[0;32m   3057\u001B[0m                 shards_done \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Tesis\\.venv\\lib\\site-packages\\datasets\\arrow_dataset.py:3458\u001B[0m, in \u001B[0;36mDataset._map_single\u001B[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001B[0m\n\u001B[0;32m   3454\u001B[0m indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[0;32m   3455\u001B[0m     \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m*\u001B[39m(\u001B[38;5;28mslice\u001B[39m(i, i \u001B[38;5;241m+\u001B[39m batch_size)\u001B[38;5;241m.\u001B[39mindices(shard\u001B[38;5;241m.\u001B[39mnum_rows)))\n\u001B[0;32m   3456\u001B[0m )  \u001B[38;5;66;03m# Something simpler?\u001B[39;00m\n\u001B[0;32m   3457\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3458\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[43mapply_function_on_filtered_inputs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3459\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3460\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3461\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_same_num_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mshard\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlist_indexes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3462\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3463\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3464\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m NumExamplesMismatchError:\n\u001B[0;32m   3465\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DatasetTransformationNotAllowedError(\n\u001B[0;32m   3466\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3467\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Tesis\\.venv\\lib\\site-packages\\datasets\\arrow_dataset.py:3320\u001B[0m, in \u001B[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001B[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001B[0m\n\u001B[0;32m   3318\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m with_rank:\n\u001B[0;32m   3319\u001B[0m     additional_args \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (rank,)\n\u001B[1;32m-> 3320\u001B[0m processed_inputs \u001B[38;5;241m=\u001B[39m function(\u001B[38;5;241m*\u001B[39mfn_args, \u001B[38;5;241m*\u001B[39madditional_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfn_kwargs)\n\u001B[0;32m   3321\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(processed_inputs, LazyDict):\n\u001B[0;32m   3322\u001B[0m     processed_inputs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   3323\u001B[0m         k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m processed_inputs\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m processed_inputs\u001B[38;5;241m.\u001B[39mkeys_to_format\n\u001B[0;32m   3324\u001B[0m     }\n",
      "Cell \u001B[1;32mIn[20], line 74\u001B[0m, in \u001B[0;36mSummarizationPreprocessor.preprocess_batch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m     72\u001B[0m inputs \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marticle\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     73\u001B[0m targets \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhighlights\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m---> 74\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_source_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     78\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_length\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Padding para que todas las secuencias tengan la misma longitud\u001B[39;49;00m\n\u001B[0;32m     79\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Retorna tensores PyTorch directamente\u001B[39;49;00m\n\u001B[0;32m     80\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     81\u001B[0m model_inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer(\n\u001B[0;32m     82\u001B[0m     targets,\n\u001B[0;32m     83\u001B[0m     max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_target_length,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     86\u001B[0m     return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# Retorna tensores PyTorch directamente\u001B[39;00m\n\u001B[0;32m     87\u001B[0m )[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_inputs\n",
      "File \u001B[1;32m~\\PycharmProjects\\Tesis\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3016\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.__call__\u001B[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   3014\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_target_context_manager:\n\u001B[0;32m   3015\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_input_mode()\n\u001B[1;32m-> 3016\u001B[0m     encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_one(text\u001B[38;5;241m=\u001B[39mtext, text_pair\u001B[38;5;241m=\u001B[39mtext_pair, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mall_kwargs)\n\u001B[0;32m   3017\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3018\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_target_mode()\n",
      "File \u001B[1;32m~\\PycharmProjects\\Tesis\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3104\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._call_one\u001B[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001B[0m\n\u001B[0;32m   3099\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   3100\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch length of `text`: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(text)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not match batch length of `text_pair`:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3101\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(text_pair)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3102\u001B[0m         )\n\u001B[0;32m   3103\u001B[0m     batch_text_or_text_pairs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(text, text_pair)) \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m text\n\u001B[1;32m-> 3104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_encode_plus(\n\u001B[0;32m   3105\u001B[0m         batch_text_or_text_pairs\u001B[38;5;241m=\u001B[39mbatch_text_or_text_pairs,\n\u001B[0;32m   3106\u001B[0m         add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[0;32m   3107\u001B[0m         padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[0;32m   3108\u001B[0m         truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[0;32m   3109\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[0;32m   3110\u001B[0m         stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[0;32m   3111\u001B[0m         is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[0;32m   3112\u001B[0m         pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[0;32m   3113\u001B[0m         padding_side\u001B[38;5;241m=\u001B[39mpadding_side,\n\u001B[0;32m   3114\u001B[0m         return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[0;32m   3115\u001B[0m         return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[0;32m   3116\u001B[0m         return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[0;32m   3117\u001B[0m         return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[0;32m   3118\u001B[0m         return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[0;32m   3119\u001B[0m         return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[0;32m   3120\u001B[0m         return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[0;32m   3121\u001B[0m         verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m   3122\u001B[0m         split_special_tokens\u001B[38;5;241m=\u001B[39msplit_special_tokens,\n\u001B[0;32m   3123\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3124\u001B[0m     )\n\u001B[0;32m   3125\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode_plus(\n\u001B[0;32m   3127\u001B[0m         text\u001B[38;5;241m=\u001B[39mtext,\n\u001B[0;32m   3128\u001B[0m         text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3146\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3147\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\Tesis\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3306\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001B[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001B[0m\n\u001B[0;32m   3296\u001B[0m \u001B[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001B[39;00m\n\u001B[0;32m   3297\u001B[0m padding_strategy, truncation_strategy, max_length, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_padding_truncation_strategies(\n\u001B[0;32m   3298\u001B[0m     padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[0;32m   3299\u001B[0m     truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3303\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3304\u001B[0m )\n\u001B[1;32m-> 3306\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_encode_plus(\n\u001B[0;32m   3307\u001B[0m     batch_text_or_text_pairs\u001B[38;5;241m=\u001B[39mbatch_text_or_text_pairs,\n\u001B[0;32m   3308\u001B[0m     add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[0;32m   3309\u001B[0m     padding_strategy\u001B[38;5;241m=\u001B[39mpadding_strategy,\n\u001B[0;32m   3310\u001B[0m     truncation_strategy\u001B[38;5;241m=\u001B[39mtruncation_strategy,\n\u001B[0;32m   3311\u001B[0m     max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[0;32m   3312\u001B[0m     stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[0;32m   3313\u001B[0m     is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[0;32m   3314\u001B[0m     pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[0;32m   3315\u001B[0m     padding_side\u001B[38;5;241m=\u001B[39mpadding_side,\n\u001B[0;32m   3316\u001B[0m     return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[0;32m   3317\u001B[0m     return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[0;32m   3318\u001B[0m     return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[0;32m   3319\u001B[0m     return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[0;32m   3320\u001B[0m     return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[0;32m   3321\u001B[0m     return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[0;32m   3322\u001B[0m     return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[0;32m   3323\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m   3324\u001B[0m     split_special_tokens\u001B[38;5;241m=\u001B[39msplit_special_tokens,\n\u001B[0;32m   3325\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3326\u001B[0m )\n",
      "File \u001B[1;32m~\\PycharmProjects\\Tesis\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:529\u001B[0m, in \u001B[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001B[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001B[0m\n\u001B[0;32m    526\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tokenizer\u001B[38;5;241m.\u001B[39mencode_special_tokens \u001B[38;5;241m!=\u001B[39m split_special_tokens:\n\u001B[0;32m    527\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tokenizer\u001B[38;5;241m.\u001B[39mencode_special_tokens \u001B[38;5;241m=\u001B[39m split_special_tokens\n\u001B[1;32m--> 529\u001B[0m encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_batch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    530\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_text_or_text_pairs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    531\u001B[0m \u001B[43m    \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    532\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_pretokenized\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    533\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    535\u001B[0m \u001B[38;5;66;03m# Convert encoding to dict\u001B[39;00m\n\u001B[0;32m    536\u001B[0m \u001B[38;5;66;03m# `Tokens` has type: Tuple[\u001B[39;00m\n\u001B[0;32m    537\u001B[0m \u001B[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001B[39;00m\n\u001B[0;32m    538\u001B[0m \u001B[38;5;66;03m#                       List[EncodingFast]\u001B[39;00m\n\u001B[0;32m    539\u001B[0m \u001B[38;5;66;03m#                    ]\u001B[39;00m\n\u001B[0;32m    540\u001B[0m \u001B[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001B[39;00m\n\u001B[0;32m    541\u001B[0m tokens_and_encodings \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    542\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_encoding(\n\u001B[0;32m    543\u001B[0m         encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    552\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m encoding \u001B[38;5;129;01min\u001B[39;00m encodings\n\u001B[0;32m    553\u001B[0m ]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
